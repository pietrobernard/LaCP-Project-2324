{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f40c116d",
   "metadata": {},
   "source": [
    "## LCPB 23-24 exercise 4 (Restricted Boltzmann Machine)\n",
    "\n",
    "- Andrea Semenzato 2130973\n",
    "- Pietro Bernardi 2097494\n",
    "- Tomàs Mezquita 2109239\n",
    "- Mariam Chokheli 2122278\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d080e64",
   "metadata": {},
   "source": [
    "We want to study the performances of an RBM, and, by looking at its learned weights and biases,\n",
    "better understand the correlations in the data (from file x_RBM_2024_exercise.dat, $N=10^4$\n",
    "configurations with L=10 bits). Use an RBM with M=3 hidden units."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633673e1",
   "metadata": {},
   "source": [
    "### Point 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb94072",
   "metadata": {},
   "source": [
    "Increase the number of contrastive divergence steps from n=1 to n=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b696e0",
   "metadata": {},
   "source": [
    "Referring to the code that was provided in the notebook, we added this loop inside the k-loop that repeats the forward and backward passes between the visible and hidden layers $CDK$-times, where $CDK = 5$ at this time as requested.\n",
    "\n",
    "```python\n",
    "h = activate(v[k], w, b, GAP)\n",
    "hf = h\n",
    "for cdk_it in range(CDK):\n",
    "    vf = activate(hf, w.T, a, GAP) #changed to hf from h\n",
    "    hf = activate(vf, w, b, GAP)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1029b115",
   "metadata": {},
   "source": [
    "### Point 2\n",
    "Compute the log-likelihood $\\mathcal{L}$ during the training, at every epoch, or every minibatch update if it\n",
    "reaches a maximum already in the first epoch. Use “t” as an index of this “time”, indicating the unit\n",
    "in the figures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c65096",
   "metadata": {},
   "source": [
    "We computed the log-likelihood by number of epochs and by minibatch. The results are shown below in the case of $M=3$ and $CD=5$.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"./ex_img/loglike_cd5_m3.png\" width=800>\n",
    "    Figure 1\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba657533",
   "metadata": {},
   "source": [
    "The log-likelihood was computed via these functions:\n",
    "\n",
    "##### getEnergy\n",
    "This function computes the energy for a given configuration (h,v) as per:\n",
    "$$\n",
    "    E(v,h) = -v\\cdot a - h\\cdot b - v^T\\cdot W\\cdot h\n",
    "$$\n",
    "```python\n",
    "def getEnergy(h, v, w, a, b):\n",
    "# a : bias when back passing : it is the visible bias\n",
    "# b : bias when forward passing : it is the hidden bias\n",
    "e0 = np.dot(np.matmul(v.T, w), h)\n",
    "e1 = np.dot(a.T, v)\n",
    "e2 = np.dot(b.T, h)\n",
    "return -1.*(e0+e1+e2)\n",
    "```\n",
    "\n",
    "##### getMeanEnergyData\n",
    "This function computes $<E>_{data}$ via:\n",
    "$$\n",
    "    <E>_{data} = \\frac{1}{N}\\sum_{n} <E(v_n,h)> = \\frac{1}{N}\\sum_{n} \\left(\\frac{\\sum_h E(v_n,h)\\cdot e^{-E(v_n,h)}}{\\sum_h e^{-E(v_n,h)}}\\right)\n",
    "$$\n",
    "where $N$ is the number of vectors being considered ($N=10^4$ in the case of the energy-per-epoch estimate, but it is equal to the batch size in case of the batch estimate).\n",
    "\n",
    "```python\n",
    "# w, a, b : model parameters\n",
    "# v : input vectors\n",
    "# k_start, k_end : range of input vectors to consider\n",
    "def getMeanEnergyData(w, a, b, v, k_start=0, k_end=N, M=3):\n",
    "    # getting all the h configurations\n",
    "    hs = list(it.product((0,1), repeat=M))\n",
    "    e = 0\n",
    "    # checking to not overshoot the number of input vectors\n",
    "    k_end_limit = k_end\n",
    "    if k_end >= N:\n",
    "        k_end_limit = N\n",
    "    for k in range(k_start,k_end_limit,1):\n",
    "        # foreach input vector v[k]\n",
    "        e_num = 0\n",
    "        e_den = 0\n",
    "        for h in hs:\n",
    "            en = getEnergy(h, v[k], w, a, b)\n",
    "            boltz = np.exp(-1.0*en)\n",
    "            e_num += (en*boltz)\n",
    "            e_den += boltz\n",
    "        # now we have the <E(v_n,h)>\n",
    "        e += (e_num/e_den)\n",
    "    return e/(k_end_limit-k_start)\n",
    "```\n",
    "\n",
    "##### getPartitionFunction\n",
    "This function computes the partition function by considering all of the $L+M$ configurations.\n",
    "```python\n",
    "def getPartitionFunction(w, a, b, L=10, M=3):\n",
    "    # generating the configurations\n",
    "    confs = list(it.product((0,1), repeat=(L+M)))\n",
    "    e_cfg = 0\n",
    "    for cfg in confs:\n",
    "        v = np.array(cfg[:L])\n",
    "        h = np.array(cfg[L:])\n",
    "        e_cfg += np.exp(-1.0*getEnergy(h, v, w, a, b))\n",
    "    # now we have the sum of all terms, hence:\n",
    "    return e_cfg\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3a69ca",
   "metadata": {},
   "source": [
    "The following figure shows how the model's parameters are adjusted during the training procedure for a model with $M=3$, over $100$ epochs:\n",
    "<div align=\"center\">\n",
    "    <img src=\"./ex_img/anim_m3_cd5.gif\" width=600>\n",
    "    Figure 2\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431b563a",
   "metadata": {},
   "source": [
    "### Point 3\n",
    "Try RBMs with different numbers of hidden units: M=1, 2, 3 (done above), 4, 5, and 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb2078d",
   "metadata": {},
   "source": [
    "The log likelihoods with $M=1,2,4,5,6$ are reported below:\n",
    "\n",
    "<div align=\"center\">\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"./ex_img/loglike_cd5_m1.png\" width=600></td>\n",
    "        <td><img src=\"./ex_img/m1_cd5/img_100.png\" width=400>\n",
    "        <br>Weights after $100$ epochs for $CD=5, M=1$.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"./ex_img/loglike_cd5_m2.png\" width=600></td>\n",
    "        <td><img src=\"./ex_img/m2_cd5/img_100.png\" width=400>\n",
    "        <br>Weights after $100$ epochs for $CD=5, M=2$.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"./ex_img/loglike_cd5_m4.png\" width=600></td>\n",
    "        <td><img src=\"./ex_img/m4_cd5/img_100.png\" width=400>\n",
    "        <br>Weights after $100$ epochs for $CD=5, M=4$.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"./ex_img/loglike_cd5_m5.png\" width=600></td>\n",
    "        <td><img src=\"./ex_img/m5_cd5/img_100.png\" width=400>\n",
    "        <br>Weights after $100$ epochs for $CD=5, M=5$.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"./ex_img/loglike_cd5_m6.png\" width=600></td>\n",
    "        <td><img src=\"./ex_img/m6_cd5/img_100.png\" width=400>\n",
    "        <br>Weights after $100$ epochs for $CD=5, M=6$.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "    Figure 3\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9134841d",
   "metadata": {},
   "source": [
    "We observed that with increasing $M$ the log-likelihood tends to stabilize at lower values and also for $M > 4$ it exhibits serious fluctuations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1737e4",
   "metadata": {},
   "source": [
    "### Point 4\n",
    "For $M=3$, plot $\\mathcal{L}$ as a function of “t”, comparing the two contrastive divergence cases (n=1 and\n",
    "n=5). Then, for n=1, plot $\\mathcal{L}$ as a function of “t”, comparing the two cases with different M."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0628dfbd",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"./ex_img/ll_m3_cd15.png\" width=600>\n",
    "    Figure 4\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c787a736",
   "metadata": {},
   "source": [
    "The result of the comparison is shown in figure 4. The log likelihoods for the two cases of contrastive divergence look almost the same, both when calculated for each epoch and each minibatch. We then compared, with $CD=1$, the case with $M=3$ with the other values of $M$.\n",
    "\n",
    "In the plot below, the case with $M=3$ is always drawn in blue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c66698",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td><img src=\"./ex_img/ll_m1_m3_cd1.png\" width=600></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><img src=\"./ex_img/ll_m2_m3_cd1.png\" width=600></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><img src=\"./ex_img/ll_m4_m3_cd1.png\" width=600></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><img src=\"./ex_img/ll_m5_m3_cd1.png\" width=600></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><img src=\"./ex_img/ll_m6_m3_cd1.png\" width=600></td>\n",
    "        </tr>\n",
    "    </table>\n",
    "    Figure 5\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9503c79",
   "metadata": {},
   "source": [
    "### Point 5\n",
    "From the weights learned by the RBM, guess the structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d66c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
